import torch
import torch.nn.functional as F
from torch.autograd import Variable
import numpy as np
import pdb, os, argparse
from tqdm import tqdm
from datetime import datetime
from model.CPD_ResNet_models import CPD_ResNet
from model.Sal_CNN import Sal_CNN
from data import get_loader
from utils import clip_gradient, adjust_lr
from DSU_test import eval_data
from tensorboardX import SummaryWriter
import torch.backends.cudnn as cudnn
from attentive_training import loss_weight, update_pseudoLabel, ContrastiveLoss


cudnn.benchmark = True


writer = SummaryWriter()
parser = argparse.ArgumentParser()
parser.add_argument('--ckpt_load', type=bool, default=False, help='whether load checkpoint or not')
parser.add_argument('--snapshot', type=int, default=None, help='load checkpoint number')


parser.add_argument('--epoch', type=int, default=40, help='epoch number')
parser.add_argument('--lr', type=float, default=1e-4, help='learning rate')
parser.add_argument('--batchsize', type=int, default=10, help='training batch size')
parser.add_argument('--trainsize', type=int, default=352, help='training dataset size')
parser.add_argument('--clip', type=float, default=0.5, help='gradient clipping margin')
parser.add_argument('--decay_rate', type=float, default=0.1, help='decay rate of learning rate')
parser.add_argument('--decay_epoch', type=int, default=200, help='every n epochs decay learning rate')
opt = parser.parse_args()


image_root = '../Dataset/train_data/images/'
depth_root = '../Dataset/train_data/depth/'
gt_root = '../Dataset/train_data/fake_mask/'
# GT is generated by CDCP [1] method that does not require any human annotation efforts.
# [1] An Innovative Salient Object Detection using Center-dark Channel Prior, ICCVW, 2017.
val_root = '../Dataset/test_data/'
validation = ['NJUD']



# build models
# Both Saliency and Depth Networks employ the CPD [2] extractor equipped with ResNet-50.
# [2] Cascaded Partial Decoder for Fast and Accurate Salient Object Detection, CVPR, 2019.
model_rgb = CPD_ResNet()
model_depth = CPD_ResNet()
model = Sal_CNN()


if opt.ckpt_load:
    model_rgb.load_state_dict(torch.load('./ckpt/' + 'DSU_rgb.pth.' + str(opt.snapshot)))
    model_depth.load_state_dict(torch.load('./ckpt/' + 'DSU_depth.pth.' + str(opt.snapshot)))
    model.load_state_dict(torch.load('./ckpt/' + 'DSU.pth.' + str(opt.snapshot)))


cuda = torch.cuda.is_available()
if cuda:
    model_rgb.cuda()
    model_depth.cuda()
    model.cuda()

params_rgb = model_rgb.parameters()
params_depth = model_depth.parameters()
params = model.parameters()

optimizer_rgb = torch.optim.Adam(params_rgb, opt.lr)
optimizer_depth = torch.optim.Adam(params_depth, opt.lr)
optimizer = torch.optim.Adam(params, opt.lr)


train_loader = get_loader(image_root, gt_root, depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)
total_step = len(train_loader)
CE = torch.nn.BCEWithLogitsLoss()
MSE = torch.nn.MSELoss()
Distance = ContrastiveLoss()





def train(train_loader, model_rgb, model_depth, model,
          optimizer_rgb, optimizer_depth,optimizer, epoch):
    model_rgb.train()
    model_depth.train()
    model.train()


    for i, pack in enumerate(tqdm(train_loader), start=1):
        iteration = i + epoch*len(train_loader)

        optimizer_rgb.zero_grad()
        optimizer_depth.zero_grad()
        optimizer.zero_grad()

        images, gts, depths,ppath,ori_data = pack
        images = Variable(images)
        gts = Variable(gts)
        depths = Variable(depths)
        ori_data = [Variable(i) for i in ori_data]
        if cuda:
            images = images.cuda()
            gts = gts.cuda()
            depths = depths.cuda()
            ori_data = [i.cuda() for i in ori_data]


        '''~~~Our DSU Framework~~~'''
        # RGB Stream
        '''Attentive Training Strategy'''
        atts_rgb,dets_rgb,_= model_rgb(images)
        pred_sal = dets_rgb.detach()

        # The update interval τ is 3, amounting to 2τ = 6 epochs in a training round.
        if (epoch + 1) % 6 <= 3 and (epoch + 1) % 6 > 0:        # Step One
                loss_rgb1 = CE(atts_rgb, gts)
                loss_rgb2 = CE(dets_rgb, gts)
                loss_rgb = (loss_rgb1 + loss_rgb2) / 2.0
        else:                                                   # Step Two
                weight, _ = loss_weight(dets_rgb, gts)
                Weighted_CE = torch.nn.BCEWithLogitsLoss(weight=weight)
                loss_rgb1 = Weighted_CE(atts_rgb, gts)
                loss_rgb2 = Weighted_CE(dets_rgb, gts)
                loss_rgb = (loss_rgb1 + loss_rgb2) / 2.0


        loss_rgb.backward()
        clip_gradient(optimizer_rgb, opt.clip)
        optimizer_rgb.step()


        # Depth Stream
        atts_depth,dets_depth,feature = model_depth(images)
        loss_depth1 = MSE(atts_depth, depths)
        loss_depth2 = MSE(dets_depth, depths)
        loss_depth = (loss_depth1 + loss_depth2) / 2.0
        loss_depth.backward()

        clip_gradient(optimizer_depth, opt.clip)
        optimizer_depth.step()


        # Fusion stream
        old_feature = feature.detach()
        S_dep, Non_S_dep, new_feature, depth_pos, depth_neg, pred_depth = model(pred_sal,depths,old_feature)

        loss_Sal_depth = MSE(S_dep,depth_pos)
        loss_NonSal_depth = MSE(Non_S_dep,depth_neg)
        loss_depth_new = MSE(pred_depth,depths)
        loss_consistency = Distance(old_feature,new_feature)/50

        loss = (loss_Sal_depth + loss_NonSal_depth + loss_depth_new + loss_consistency)/4.0

        loss.backward()
        clip_gradient(optimizer, opt.clip)
        optimizer.step()


        if (epoch + 1) % 6 == 0:
                '''Update pseudo Label'''
                # Note that: we need to obtain original data with no augmentation to replace the fake label
                with torch.no_grad():
                    if hasattr(torch.cuda, 'empty_cache'):
                        torch.cuda.empty_cache()
                    img_ori,gt_ori,depth_ori = ori_data
                    _, det_rgb, _ = model_rgb(img_ori)
                    pred_saliency = det_rgb.detach()

                    _, _, feature1 = model_depth(img_ori)
                    old_feature1 = feature1.detach()
                    S_dep1, Non_S_dep1, _, _, _, _ = model(pred_saliency, depth_ori, old_feature1)
                    S_depth1 = S_dep1.detach()
                    Non_S_depth1 = Non_S_dep1.detach()

                    _, l_weight = loss_weight(pred_saliency, gt_ori)
                    update_pseudoLabel(l_weight,ppath,S_depth1,Non_S_depth1,pred_saliency,int(epoch+1))


        '''~~~END~~~'''


        if i % 400 == 0 or i == total_step:
            print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss_rgb: {:.4f} Loss_depth_sal: {:0.4f}'.
                  format(datetime.now(), epoch, opt.epoch, i, total_step, loss_rgb.data, loss.data))
        writer.add_scalar('Loss/rgb', loss_rgb.item(), iteration)
        writer.add_scalar('Loss/depth', loss_depth.item(), iteration)
        writer.add_scalar('Loss/Sal_depth', loss.item(), iteration)


    save_path = 'ckpt/'

    if not os.path.exists(save_path):
        os.makedirs(save_path)
    if (epoch+1) % 2 == 0:
        torch.save(model_rgb.state_dict(), save_path + 'DSU_rgb.pth' + '.%d' % (epoch+1))
        torch.save(model_depth.state_dict(), save_path + 'DSU_depth.pth' + '.%d' % (epoch + 1))
        torch.save(model.state_dict(), save_path + 'DSU.pth' + '.%d' % (epoch + 1))


print("Let's go!")
for epoch in range(1, opt.epoch):
    adjust_lr(optimizer_rgb, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)
    adjust_lr(optimizer_depth, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)
    adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)
    train(train_loader, model_rgb, model_depth, model,
          optimizer_rgb, optimizer_depth,optimizer, epoch)
    if (epoch+1) % 2 == 0:
        ckpt_name = '.' + str(epoch+1)
        eval_data(val_root, validation,ckpt_name)
    if epoch >= opt.epoch -1:
        writer.close()
